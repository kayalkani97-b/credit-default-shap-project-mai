# Credit Default Prediction â€“ Interpretable Machine Learning (SHAP Project)

This project predicts **credit card default** using XGBoost and RandomForest models, followed by global and local interpretability using **SHAP (SHapley Additive exPlanations)**.

The project is structured according to explainable ML requirements for model transparency and fairness.

---

## ğŸ“‚ Repository Structure

```
credit-default-shap-project/
â”‚
â”œâ”€â”€ project.ipynb
â”œâ”€â”€ report.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ default_credit.xls (or data file)
â”‚
â””â”€â”€ plots/
    â”œâ”€â”€ global_shap_summary.png
    â”œâ”€â”€ global_shap_bar.png
    â”œâ”€â”€ local_false_negative.png
    â”œâ”€â”€ local_false_positive.png
    â””â”€â”€ local_borderline_correct.png
```

---

## ğŸ“Š Models Used
- **XGBoost Classifier**
- **RandomForest Classifier**

### Evaluation Metrics
- **AUC Score**
- **F1 Score**
- Confusion Matrix & Classification Report

---

## ğŸ” Interpretability
This project uses **SHAP** for:

### âœ” Global Interpretability  
- Top 10 most important features  
- Summary plot  
- Feature importance bar plot  

### âœ” Local Interpretability  
- False Negative case  
- False Positive case  
- Borderline correct prediction  

---

## ğŸ›  How to Run the Project

### Option 1 â€” Google Colab (Recommended)
1. Upload the dataset and notebook  
2. Install packages using `requirements.txt`  
3. Run cells from top to bottom  

### Option 2 â€” Local Machine
```
pip install -r requirements.txt
jupyter notebook project.ipynb
```

---

## ğŸ§  Key Insights
- Payment history (PAY_0, PAY_2, PAY_3) and recent payment amounts (PAY_AMT6, PAY_AMT4) are leading predictors.
- SHAP reveals true feature influence more accurately than XGBoost built-in importance.
- Local explanations highlight model errors and risk patterns.

---

## ğŸ“ Contact
If you have any questions about the project or execution, feel free to reach out.

---

